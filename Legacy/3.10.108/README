HOWTO: Enable SR-IOV with  Mellanox OFED driver on upstream 3.10.88 kernel for
Linux VM on Hyper-V and Azure environment.

1. Follow the below instruction to enable SR-IOV on 3.10.88 kernel

1.1 checkout the upstream 3.10.108 kernel
https://git.kernel.org/pub/scm/linux/kernel/git/stable/linux-stable.git/commit/?h=linux-3.10.y&id=e7a59c7f266809d17dcde20fd2055e23e7eb6895

1.2 apply the 3 patches
0001-vmbus-backport-for-3.10.108.patch
0002-hack-pci-res-code-to-make-OFED-driver-work.patch
0003-uncomment-the-hv_utils-driver.patch

1.3 use the "kernel-config" as the .config and build & install the kernel/drivers.

1.4 If you're on a local Hyper-V host, add a Mellanox ConnectX-3 VF to the VM and "lspci" should show
0002:00:02.0 Network controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function]

If your VM is on Azure, follow this link to enable Accelerated Networking (i.e. SR-IOV for network)
 https://docs.microsoft.com/en-us/azure/virtual-network/create-vm-accelerated-networking-cli

Kernel 3.10.108  inbox mellanox driver does not support SR-IOV, please use the OFED driver.

2. Steps to enable the OFED driver

2.1 Download the latest OFED driver from:
http://www.mellanox.com/page/products_dyn?product_family=26&mtag=linux_sw_drivers
*select related distribution.

2.2 Uncompress the src/MLNX_OFED_SRC-4.2-1.2.0.0.tgz, and run
src/MLNX_OFED_SRC-4.2-1.2.0.0/install.pl. After installing the necessary
prerequisite packages, we'll start to build the OFED drivers and this can take ~30
minutes, and finally the generated drivers will be installed automatically with
no error.

2.3 Reboot the VM, and the MLX OFED driver should load fine.

root@u1604:~# lspci -s 0002:00:02.0 -vvv
0002:00:02.0 Network controller: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function]
        Subsystem: Mellanox Technologies MT27500/MT27520 Family [ConnectX-3/ConnectX-3 Pro Virtual Function]
        Control: I/O- Mem+ BusMaster+ SpecCycle- MemWINV- VGASnoop- ParErr- Stepping- SERR- FastB2B- DisINTx-
        Status: Cap+ 66MHz- UDF- FastB2B- ParErr- DEVSEL=fast >TAbort- <TAbort- <MAbort- >SERR- <PERR- INTx-
        Latency: 0
        Region 2: Memory at fe0000000 (64-bit, prefetchable) [size=8M]
        Capabilities: [60] Express (v2) Endpoint, MSI 00
                DevCap: MaxPayload 512 bytes, PhantFunc 0, Latency L0s <64ns, L1 <1us
                        ExtTag- AttnBtn- AttnInd- PwrInd- RBE- FLReset+
                DevCtl: Report errors: Correctable- Non-Fatal- Fatal- Unsupported-
                        RlxdOrd- ExtTag- PhantFunc- AuxPwr- NoSnoop- FLReset-
                        MaxPayload 128 bytes, MaxReadReq 128 bytes
                DevSta: CorrErr- UncorrErr- FatalErr- UnsuppReq- AuxPwr- TransPend-
                LnkCap: Port #0, Speed 8GT/s, Width x8, ASPM not supported, Exit Latency L0s <64ns, L1 <1us
                        ClockPM- Surprise- LLActRep- BwNot- ASPMOptComp-
                LnkCtl: ASPM Disabled; RCB 64 bytes Disabled- CommClk-
                        ExtSynch- ClockPM- AutWidDis- BWInt- AutBWInt-
                LnkSta: Speed unknown, Width x0, TrErr- Train- SlotClk- DLActive- BWMgmt- ABWMgmt-
                DevCap2: Completion Timeout: Range ABCD, TimeoutDis+, LTR-, OBFF Not Supported
                DevCtl2: Completion Timeout: 50us to 50ms, TimeoutDis-, LTR-, OBFF Disabled
                LnkSta2: Current De-emphasis Level: -6dB, EqualizationComplete-, EqualizationPhase1-
                         EqualizationPhase2-, EqualizationPhase3-, LinkEqualizationRequest-
        Capabilities: [9c] MSI-X: Enable+ Count=108 Masked-
                Vector table: BAR=2 offset=00002000
                PBA: BAR=2 offset=00003000
        Capabilities: [40] Power Management version 0
                Flags: PMEClk- DSI- D1- D2- AuxCurrent=0mA PME(D0-,D1-,D2-,D3hot-,D3cold-)
                Status: D0 NoSoftRst- PME-Enable- DSel=0 DScale=0 PME-
        Kernel driver in use: mlx4_core
        Kernel modules: mlx4_core

root@u1604:~# dmesg |grep -i mlx
[    6.898018] mlx_compat: module verification failed: signature and/or required key missing - tainting kernel
[    6.981022] mlx4_core: Mellanox ConnectX core driver v4.2-1.2.0
[    6.981807] mlx4_core: Initializing 0002:00:02.0
[    6.985014] mlx4_core 0002:00:02.0: Detected virtual function - running in slave mode
[    6.985731] mlx4_core 0002:00:02.0: Sending reset
[    6.986502] mlx4_core 0002:00:02.0: Sending vhcr0
[    6.988599] mlx4_core 0002:00:02.0: HCA minimum page size:512
[    6.989850] mlx4_core 0002:00:02.0: Timestamping is not supported in slave mode
[    6.990563] mlx4_core: device is working in RoCE mode: Unknown
[    6.991234] mlx4_core: gid_type 0 for UD QPs is not supported by the device, gid_type 3 was chosen instead
[    6.991897] mlx4_core: UD QP Gid type is: Unknown
[    6.995134] mlx4_core 0002:00:02.0: irq 40 for MSI/MSI-X
[    6.995903] mlx4_core 0002:00:02.0: irq 41 for MSI/MSI-X
[    6.996692] mlx4_core 0002:00:02.0: irq 42 for MSI/MSI-X
[    6.997450] mlx4_core 0002:00:02.0: irq 43 for MSI/MSI-X
[    6.998203] mlx4_core 0002:00:02.0: irq 44 for MSI/MSI-X
[    6.998936] mlx4_core 0002:00:02.0: irq 45 for MSI/MSI-X
[    6.999672] mlx4_core 0002:00:02.0: irq 46 for MSI/MSI-X
[    7.000437] mlx4_core 0002:00:02.0: irq 47 for MSI/MSI-X
[    7.001179] mlx4_core 0002:00:02.0: irq 48 for MSI/MSI-X
[    7.214335] mlx4_en: Mellanox ConnectX HCA Ethernet driver v4.2-1.2.0
[    7.215712] mlx4_en 0002:00:02.0: Activating port:1
[    7.233663] mlx4_en: 0002:00:02.0: Port 1: Using 8 TX rings
[    7.234364] mlx4_en: 0002:00:02.0: Port 1: Using 8 RX rings
[    7.235156] mlx4_en: 0002:00:02.0: Port 1: Initializing port
[    7.236279] mlx4_core 0002:00:02.0 eth2: joined to eth1
[    7.887110] <mlx4_ib> mlx4_ib_add: mlx4_ib: Mellanox ConnectX InfiniBand driver v4.2-1.2.0
[    7.889074] <mlx4_ib> mlx4_ib_add: counter index 10 for port 1 allocated 1
[    7.890677] ib_query_pkey failed (-1) for mlx4_0 (index 0)
[    7.892176] mlx4_core 0002:00:02.0: mlx4_ib: multi-function enabled
[    7.893222] mlx4_core 0002:00:02.0: mlx4_ib: operating in qp1 tunnel mode
[   11.078676] mlx4_en: enP2p0s2: Steering Mode 2
[   11.099536] mlx4_en: enP2p0s2: Link Up

Verify:

Check for activity on the VF using "ethtool -S eth0 | grep vf_" command. If you see output such as below, SR-IOV (accelerated networking)
is working.

vf_rx_packets: 992956
vf_rx_bytes: 2749784180
vf_tx_packets: 2656684
vf_tx_bytes: 1099443970
vf_tx_dropped: 0

Note: Hyper-V: the patchset backported the transparent SR-IOV VF patch, so we should set IP address to
the ethX interface and not the VF interface.

